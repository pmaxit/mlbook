{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Custom dataset\n",
    "\n",
    "In the last notebook, we looked at how to build computer vision models on in-built datasets in pytorch (FashionMNIST). Steps we took are similar across many different problems in computer vision. \n",
    "\n",
    "- Find a dataset\n",
    "- turn dataset into numbers\n",
    "- build a model\n",
    "- find patterns\n",
    "\n",
    "Pytorch has many built-in datasets used for a wide number of machine learning benchmarks. However you'll often want to use your own `custom dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset\n",
    "\n",
    "Here in this tutorial, we will use another awesome library called \"datasets\" from huggingface team to create our own dataset. A custom dataset is just a fancy name to bring your own data to pytorch. For example,\n",
    "\n",
    "- if we are building a food image classification app like `Nutrify`, our custom dataset might be images of food\n",
    "- or If we are building to build a sound classification app, our custom dataset might be sound samples alongside with their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch provides some libraries to help deal with different domain problems\n",
    "\n",
    "- **TorchVision** \n",
    "Helps in computer vision task\n",
    "\n",
    "- **TOrchText**\n",
    "Helps in NLP\n",
    "\n",
    "- **TorchAudio**\n",
    "Helps in audio processing\n",
    "\n",
    "- **TorchRec**\n",
    "How do we recommend similar products?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we're going to cover\n",
    "\n",
    "\n",
    "We are going to be applying the PyTorch Workflow we covered in previous notebooks to a computer vision problem. But instead of using an in-built pytorch dataset, we're going to be using our own dataset of Pizza, steak and sushi images. The goal will be to load these images and then build a model to train and predict on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to use `datasets` library from huggingface and use some pytorch domain libraries to help in data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- list of topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch specific libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Common libraries\n",
    "\n",
    "# Huggingface libraries\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: If you're using Google Colab, and you don't have a GPU turned on yet, it's now time to turn one on via `Runtim -> Change runtime type -> Hardware accelerator -> GPU`. If you do this, your runtime will likely reset and you'll have to run all the cells above by going `Runtime -> Run before`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing first, we need some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d79b13253c14392bbbe25f9c895c569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099a4e6785814c7fa7d2b55533dcfd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset food101/default (download: 4.65 GiB, generated: 4.77 GiB, post-processed: Unknown size, total: 9.43 GiB) to /Users/puneetg/.cache/huggingface/datasets/food101/default/0.0.0/7cebe41a80fb2da3f08fcbef769c8874073a86346f7fb96dc0847d4dfc318295...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854b72fcab8a45fba458eca21a56433e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets.load_dataset('food101')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to see where data came from you see the following resources:\n",
    "- Original food101 dataset and paper website\n",
    "- torchvision dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebcbe93e7a17a15e0b6fda216993a68177c05d9ec95be5dd879d0ab806b8db74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
