{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy is mapping from states to actions telling what action to take at each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy can be probalistic and denoted by \n",
    "$$\\pi$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewards\n",
    "\n",
    "Signal what is expected; design can be tricky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we give only one positive signal at the end then it won't have any motivation to solve the problem quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(s\\prime, r | s, a) $$ \n",
    "\n",
    "= probability of getting state  and reward r given state s and action a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we don't know the value of this until we `interact` with the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ E(s_t) = \\sum(r_t) \\sum(P(s_{t+1}, r | S_t, a))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discounting\n",
    "\n",
    "$$G_t = R_t + \\gamma * G_{t+1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor critic method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor approximates policy\n",
    "\n",
    "state is the input and output is the action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critic approximates how good the action is $ V(s) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Difference (TD) learning\n",
    "\n",
    "Learn at each time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost of the critic\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
